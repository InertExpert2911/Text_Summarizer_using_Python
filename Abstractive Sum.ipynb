{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention import AttentionLayer \n",
    "# Attention is a simple vector.\n",
    "# It allows machine translator to look over all the information the original sentence holds, \n",
    "# then generates the proper word according to the current word it works on and the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# Support for regular expressions\n",
    "import re\n",
    "\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "# Importing BeautifulSoup4 is a library for pulling out data from HTML and XML files.\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Using keras\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Using NATURAL LANGUAGE TOOL-KIT\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Using Tensorflow\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\") ## Doesn't display warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Reviews.csv\",nrows=15000) # Reading the dataset\n",
    "# The data set has 500,000 data sets but i have used only 100,000.\n",
    "# We can use more but i dont have the computational power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id   ProductId          UserId                      ProfileName  \\\n",
      "0          1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1          2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2          3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3          4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4          5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "...      ...         ...             ...                              ...   \n",
      "14995  14996  B000EGZ99M   AH720G9X1MIQ8                              KJT   \n",
      "14996  14997  B000EGZ99M  A1MW2HEG4LF56B                     S. Mariconda   \n",
      "14997  14998  B000EGZ99M  A1GY0FE07QFFLF                   Arlington Cory   \n",
      "14998  14999  B000EGZ99M  A2N8ZFDXI5T6BW                        Beverleaf   \n",
      "14999  15000  B000EGZ99M   ACLTZ4KSPHG1N                jodimae \"jodimae\"   \n",
      "\n",
      "       HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                         1                       1      5  1303862400   \n",
      "1                         0                       0      1  1346976000   \n",
      "2                         1                       1      4  1219017600   \n",
      "3                         3                       3      2  1307923200   \n",
      "4                         0                       0      5  1350777600   \n",
      "...                     ...                     ...    ...         ...   \n",
      "14995                     1                       1      5  1255824000   \n",
      "14996                     3                       4      5  1170633600   \n",
      "14997                     0                       0      5  1326585600   \n",
      "14998                     0                       0      5  1322179200   \n",
      "14999                     0                       0      5  1316736000   \n",
      "\n",
      "                                    Summary  \\\n",
      "0                     Good Quality Dog Food   \n",
      "1                         Not as Advertised   \n",
      "2                     \"Delight\" says it all   \n",
      "3                            Cough Medicine   \n",
      "4                               Great taffy   \n",
      "...                                     ...   \n",
      "14995          Rice Select Whole Wheat Orzo   \n",
      "14996    Absolutely wonderful comfort food!   \n",
      "14997  Whole Wheat Orzo Tasty and Versatile   \n",
      "14998             Whole grain deliciousness   \n",
      "14999                                 Great   \n",
      "\n",
      "                                                                                                                                                                                                          Text  \n",
      "0      I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...  \n",
      "1               Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".  \n",
      "2      This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...  \n",
      "3      If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...  \n",
      "4                                                                 Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.  \n",
      "...                                                                                                                                                                                                        ...  \n",
      "14995                                                 Could no longer find Rice Select Whole Wheat Orzo at the grocery store.  Amazon had the best on-line price.  This orzo is a delicious and healthy pasta!  \n",
      "14996  I discovered this in our local QFC grocery store, which is the only place I've ever seen it, and Amazon's price is much better as I paid $8 for one package.<br /><br />Growing up, my mom used to m...  \n",
      "14997  Hard to find whole wheat orzo in supermarket, happy to find it on Amazon. Tasty in hot soup, as a main or side dish with vegetables, seafood or meat. Can also be used anywhere you would use cousco...  \n",
      "14998         This product is delicious, and healthier than regular orzo.  What I especially love is the packaging:  the jar with screw-top is much more convenient for storage and allows for easy measuring.  \n",
      "14999  We love this whole wheat pasta. When my husband was diagnoses with diabetes last year we decided to go with whole wheat pasta, he loves pasta but the type made from refined white flour was really ...  \n",
      "\n",
      "[15000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data) # Printd data of the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'],inplace=True) # drop the duplicates.\n",
    "\n",
    "data.dropna(axis=0,inplace=True) # drop rows and columns that have NULL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14413 entries, 0 to 14999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Id                      14413 non-null  int64 \n",
      " 1   ProductId               14413 non-null  object\n",
      " 2   UserId                  14413 non-null  object\n",
      " 3   ProfileName             14413 non-null  object\n",
      " 4   HelpfulnessNumerator    14413 non-null  int64 \n",
      " 5   HelpfulnessDenominator  14413 non-null  int64 \n",
      " 6   Score                   14413 non-null  int64 \n",
      " 7   Time                    14413 non-null  int64 \n",
      " 8   Summary                 14413 non-null  object\n",
      " 9   Text                    14413 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info() # Get the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "# A dictionary to use when expanding the contractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"you've\", \"isn't\", 'me', 'a', 't', 'out', 'ain', 'she', 're', 'before', 'under', 'll', 'my', 's', 'above', \"should've\", 'will', 'by', 'ma', 'of', 'few', 'at', 'what', 'm', 'as', 'other', \"weren't\", 'some', \"couldn't\", 'its', 'no', \"hadn't\", 'd', 'we', 'this', 'her', 'do', 'is', 'having', 'these', 'off', 'against', 'when', 'than', 'mightn', 'such', \"you'd\", 'won', \"doesn't\", 'until', 'theirs', 'too', 'herself', 'y', 'which', 'during', 'being', 'had', 'for', 'because', 'himself', 'so', 'hers', \"mustn't\", 'those', 'below', 'his', 'doesn', 'themselves', 'any', 'again', \"haven't\", 'him', 'between', \"you'll\", \"don't\", 'then', 'very', \"it's\", 'shan', 'where', 'more', 'yourselves', 'all', 'most', 'each', 'through', 'isn', 'only', 'am', 'wouldn', 'our', 'don', 'be', 'did', 'does', 'their', \"she's\", 'mustn', 'and', 'on', 'up', 'further', 'hasn', 'doing', 'wasn', 'but', 'aren', 'he', 'or', 'it', 'an', \"shouldn't\", 'weren', 'there', 'couldn', 'didn', \"you're\", 'why', \"mightn't\", 'you', 'the', 'same', 'own', \"didn't\", \"that'll\", 'just', 'who', 'myself', 'has', \"shan't\", 've', 'with', \"wouldn't\", 'about', 'i', 'how', \"hasn't\", 'from', 'while', 'yourself', 'not', 'nor', 'been', 'down', 'once', \"aren't\", 'if', 'them', 'that', 'o', 'to', 'over', 'are', 'were', 'they', 'have', 'in', 'shouldn', 'needn', \"won't\", 'here', 'now', 'hadn', 'haven', 'ourselves', 'itself', 'after', 'whom', 'yours', 'should', 'into', \"wasn't\", \"needn't\", 'both', 'your', 'ours', 'can', 'was'}\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text,num):\n",
    "    newString = text.lower() # Covert to lower-case\n",
    "    \n",
    "    newString = BeautifulSoup(newString, \"lxml\").text # Extract the data\n",
    "    \n",
    "    # Remove HTML tags.\n",
    "    # Remove 's\n",
    "    # Remove text inside parathesis ()\n",
    "    # Remove punctuation and special characters\n",
    "    # Remove stop words\n",
    "    # Remove short words\n",
    "    \n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString) \n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)   # Remove 's\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                \n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the defined function.\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:5] # Some pre-processed reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the fuction text_cleaner\n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy',\n",
       " 'nice taffy',\n",
       " 'great just as good as the expensive brands',\n",
       " 'wonderful tasty taffy',\n",
       " 'yay barley',\n",
       " 'healthy dog food']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_summary[:10] # Summary of some reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_text']=cleaned_text # Store the text\n",
    "data['cleaned_summary']=cleaned_summary # Store the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty rows\n",
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9447955003124783\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=8):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['cleaned_summary']))\n",
    "# 94% of the summaries length is below 8 so, we have set max to 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len=30\n",
    "max_summary_len=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_summary=np.array(data['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer to review the training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 67.63814180929096\n",
      "Total Coverage of rare words: 7.532805149789552\n"
     ]
    }
   ],
   "source": [
    "# Defining rare words if thresh < 4 is considered as a rare word.\n",
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n",
    "\n",
    "# tot_cnt - gives the size of vocabulary (which means every unique words in the text)\n",
    "\n",
    "# cnt - gives the no. of rare words whose count falls below threshold (<4)\n",
    "\n",
    "# tot_cnt - cnt gives me the top most common words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3310"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 83.32840673958025\n",
      "Total Coverage of rare words: 12.487614150665488\n"
     ]
    }
   ],
   "source": [
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7149, 7149)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_counts['sostok'],len(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows that contain START\n",
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows that contain END\n",
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 100)      331000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 30, 300), (N 481200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 30, 300), (N 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    56500       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 30, 300), (N 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 565)    339565      concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,312,165\n",
      "Trainable params: 3,312,165\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input (shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6709 samples, validate on 750 samples\n",
      "Epoch 1/50\n",
      "6709/6709 [==============================] - 123s 18ms/sample - loss: 2.8532 - val_loss: 2.3644\n",
      "Epoch 2/50\n",
      "6709/6709 [==============================] - 134s 20ms/sample - loss: 2.3263 - val_loss: 2.2680\n",
      "Epoch 3/50\n",
      "6709/6709 [==============================] - 137s 20ms/sample - loss: 2.2368 - val_loss: 2.1949\n",
      "Epoch 4/50\n",
      "6709/6709 [==============================] - 138s 21ms/sample - loss: 2.1701 - val_loss: 2.1471\n",
      "Epoch 5/50\n",
      "6709/6709 [==============================] - 141s 21ms/sample - loss: 2.1281 - val_loss: 2.1180\n",
      "Epoch 6/50\n",
      "6709/6709 [==============================] - 140s 21ms/sample - loss: 2.0902 - val_loss: 2.0934\n",
      "Epoch 7/50\n",
      "6709/6709 [==============================] - 141s 21ms/sample - loss: 2.0526 - val_loss: 2.0967\n",
      "Epoch 8/50\n",
      "6709/6709 [==============================] - 140s 21ms/sample - loss: 2.0178 - val_loss: 2.0569\n",
      "Epoch 9/50\n",
      "6709/6709 [==============================] - 139s 21ms/sample - loss: 1.9836 - val_loss: 2.0726\n",
      "Epoch 10/50\n",
      "6709/6709 [==============================] - 140s 21ms/sample - loss: 1.9461 - val_loss: 2.0269\n",
      "Epoch 11/50\n",
      "6709/6709 [==============================] - 139s 21ms/sample - loss: 1.9107 - val_loss: 2.0262\n",
      "Epoch 12/50\n",
      "6709/6709 [==============================] - 138s 21ms/sample - loss: 1.8767 - val_loss: 2.0023\n",
      "Epoch 13/50\n",
      "6709/6709 [==============================] - 135s 20ms/sample - loss: 1.8370 - val_loss: 1.9980\n",
      "Epoch 14/50\n",
      "6709/6709 [==============================] - 121s 18ms/sample - loss: 1.8077 - val_loss: 1.9745\n",
      "Epoch 15/50\n",
      "6709/6709 [==============================] - 123s 18ms/sample - loss: 1.7713 - val_loss: 1.9643\n",
      "Epoch 16/50\n",
      "6709/6709 [==============================] - 122s 18ms/sample - loss: 1.7389 - val_loss: 1.9669\n",
      "Epoch 17/50\n",
      "6709/6709 [==============================] - 122s 18ms/sample - loss: 1.7057 - val_loss: 1.9680\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3zc1Znv8c+jXq3eJSN3y5YlV6ohLtjYdJYAWUKSZTchfcndwALJkk3uvbvL3WTZJJsAIUBIAiEhYHqzccEYY4zcZBUbF1zUJRdZki3J0jz3j9/IFrJky9JIo5l53q/XvGY0c+Y3jwT+6uj8zu8cUVWMMcb4viBvF2CMMcYzLNCNMcZPWKAbY4yfsEA3xhg/YYFujDF+IsRbH5ycnKy5ubne+nhjjPFJmzZtalDVlN5e81qg5+bmUlRU5K2PN8YYnyQi+/t6zYZcjDHGT1igG2OMn7BAN8YYP+G1MXRjjBmIkydPUlFRQWtrq7dLGVIRERFkZ2cTGhra7/dYoBtjfEpFRQWxsbHk5uYiIt4uZ0ioKocOHaKiooIxY8b0+3025GKM8Smtra0kJSX5bZgDiAhJSUnn/VeIBboxxuf4c5h3Gcj36HOBvrOmiX9/s5zj7R3eLsUYY0YUnwv0iiPHeXztXkoqj3m7FGNMADp69CiPPPLIeb/v6quv5ujRo0NQ0Wk+F+gF2fEAbDs4tD8YY4zpTV+B3tnZedb3vfnmm8THxw9VWYAPznJJiQ0nKz6SbRUW6MaY4Xf//fezZ88epk+fTmhoKDExMWRkZLB161bKysq48cYbOXjwIK2trdx9993cddddwOnlTpqbm1m6dClz585l/fr1ZGVl8corrxAZGTno2nwu0AEKc+Is0I0x/OS1UsqqPDv8OiVzFP963dQ+X3/ooYcoKSlh69atrFmzhmuuuYaSkpJT0wufeuopEhMTOXHiBHPmzOHmm28mKSnpM8fYtWsXzz33HL/97W+59dZbefHFF7njjjsGXbvPDbkAFGbHc/DwCQ41t3m7FGNMgLvwwgs/M1f8l7/8JYWFhVx88cUcPHiQXbt2nfGeMWPGMH36dABmzZrFvn37PFKLT/bQu8bRiysbmT8p1cvVGGO85Ww96eESHR196vGaNWt49913+fDDD4mKimLevHm9ziUPDw8/9Tg4OJgTJ054pJZz9tBFJEdEVotIuYiUisjdvbSJE5HXRGSbu82dHqmuD9Oy4xCxE6PGmOEXGxtLU1NTr681NjaSkJBAVFQUO3bsYMOGDcNaW3966B3A91V1s4jEAptEZIWqlnVr822gTFWvE5EUYKeIPKuq7UNRdEx4CBNSYyzQjTHDLikpicsuu4z8/HwiIyNJS0s79dqSJUt47LHHKCgoYNKkSVx88cXDWts5A11Vq4Fq9+MmESkHsoDuga5ArDiXNsUAh3F+EQyZgux4Vu+oQ1UD4qoxY8zI8ac//anX58PDw3nrrbd6fa1rnDw5OZmSkpJTz99zzz0eq+u8ToqKSC4wA/iox0u/AvKAKmA7cLequnp5/10iUiQiRfX19QMquEthTjyHWtqpOOKZsSdjjPF1/Q50EYkBXgS+p6o95wldBWwFMoHpwK9EZFTPY6jq46o6W1Vnp6T0uiVev03vusDIpi8aYwzQz0AXkVCcMH9WVZf10uROYJk6dgOfApM9V+aZJqXHEhYcRHFF41B+jDHG+Iz+zHIR4EmgXFUf7qPZAWChu30aMAnY66kiexMWEsSUzFFstROjxhgD9G+Wy2XAl4DtIrLV/dwPgNEAqvoY8H+Ap0VkOyDAfaraMAT1fsb0nHieLzpIp0sJDrITo8aYwNafWS7rcEL6bG2qgMWeKqq/CrLjeHr9PnbXNTMpPXa4P94YY0YUn7z0v0thjq28aIwZXgNdPhfg5z//OcePH/dwRaf5dKCPSYomNiKErTbTxRgzTEZyoPvkWi5dgoKEguw4ii3QjTHDpPvyuYsWLSI1NZXnn3+etrY2brrpJn7yk5/Q0tLCrbfeSkVFBZ2dnTz44IPU1tZSVVXF/PnzSU5OZvXq1R6vzacDHZyVFx9fu5fWk51EhAZ7uxxjzHB6636o2e7ZY6ZPg6UP9fly9+Vzly9fzgsvvMDGjRtRVa6//nrWrl1LfX09mZmZvPHGG4CzxktcXBwPP/wwq1evJjk52bM1u/n0kAs44+gdLqWs2rakM8YMr+XLl7N8+XJmzJjBzJkz2bFjB7t27WLatGm8++673Hfffbz//vvExcUNSz1+0UMH58TozNEJXq7GGDOsztKTHg6qygMPPMDXv/71M17btGkTb775Jg888ACLFy/mRz/60ZDX4/M99PS4CNJGhdtMF2PMsOi+fO5VV13FU089RXNzMwCVlZXU1dVRVVVFVFQUd9xxB/fccw+bN28+471Dwed76OD00m0JAGPMcOi+fO7SpUu5/fbbueSSSwCIiYnhmWeeYffu3dx7770EBQURGhrKo48+CsBdd93F0qVLycjIGJKToqKqHj9of8yePVuLioo8cqxfr97NT9/ZybYfLSYuKtQjxzTGjEzl5eXk5eV5u4xh0dv3KiKbVHV2b+19fsgFTo+jF1fasIsxJnD5RaBPy3bOINuwizEmkPlFoMdFhjI2OdpWXjQmQHhrqHg4DeR79ItAB2c+us10Mcb/RUREcOjQIb8OdVXl0KFDREREnNf7/GKWC0BhdhwvbamkprGV9Ljz+yEYY3xHdnY2FRUVDHYby5EuIiKC7Ozs83qP3wR6gXvlxa0Hj7IkLt3L1RhjhkpoaChjxozxdhkjkt8MuUzJGEVIkNgeo8aYgOU3gR4RGszkjFhbedEYE7D8JtDBfcXowUZcLv89WWKMMX3xr0DPiaeprYO9DS3eLsUYY4adfwV61xWjNuxijAlAfhXo41NjiAoLtvnoxpiA5FeBHhwkTMuKY6stAWCMCUB+FejgjKOXVx2jvcPl7VKMMWZY+V+gZ8fT3uliR41tSWeMCSz+F+g5zsqLNo5ujAk0fhfoWfGRJEWHsc3G0Y0xAeacgS4iOSKyWkTKRaRURO7uo908EdnqbvOe50vtHxGxlReNMQGpP4tzdQDfV9XNIhILbBKRFapa1tVAROKBR4AlqnpARFKHqN5+KcyOZ/XOOprbOogJ95v1x4wx5qzO2UNX1WpV3ex+3ASUA1k9mt0OLFPVA+52dZ4u9HwU5MShCttt2MUYE0DOawxdRHKBGcBHPV6aCCSIyBoR2SQiX+7j/XeJSJGIFA3lWsZdV4zayovGmEDS70AXkRjgReB7qtpzTmAIMAu4BrgKeFBEJvY8hqo+rqqzVXV2SkrKIMo+u8ToMEYnRtkSAMaYgNKvAWYRCcUJ82dVdVkvTSqABlVtAVpEZC1QCHzisUrPU0F2HFsOWKAbYwJHf2a5CPAkUK6qD/fR7BXgchEJEZEo4CKcsXavmZ4TT+XRE9Q3tXmzDGOMGTb96aFfBnwJ2C4iW93P/QAYDaCqj6lquYi8DRQDLuAJVS0ZioL7qzDn9MqLC/PSvFmKMcYMi3MGuqquA6Qf7X4K/NQTRXnC1MxRBIlzxagFujEmEPjdlaJdosJCmJgWaysvGmMCht8GOjjj6MUVR1G1LemMMf7PrwO9IDueo8dPcuDwcW+XYowxQ86vA71r5cWttq6LMSYA+HWgT0yLJSI0iGIbRzfGBAC/DvTQ4CCmZsbZyovGmIDg14EOzrouJVWNdHTalnTGGP/m/4GeE0frSRef1DZ7uxRjjBlS/h/otvKiMSZA+H2gX5AURVxkqI2jG2P8nt8HuohQkB1ne4waY/ye3wc6OFeMflLbxPH2Dm+XYowxQyYgAr0wO55Ol1Ja1XNfDmOM8R8BEegF7itGbRzdGOPPAiLQU2MjyIyLsHF0Y4xfC4hAB2fDC+uhG2P8WcAEekF2PAcOH+dIS7u3SzHGmCERMIHetfKiXWBkjPFXARPo07LiEMFWXjTG+K2ACfTYiFDGpcTYOLoxxm8FTKCDMx99m21JZ4zxUwEV6NNz4mhobqeqsdXbpRhjjMcFVKAXdK28aMMuxhg/FFCBPjkjlrDgIAt0Y4xfCqhADw8JJi9zlE1dNMb4pXMGuojkiMhqESkXkVIRufssbeeISKeIfN6zZXpOYXYc2ysa6XTZiVFjjH/pTw+9A/i+quYBFwPfFpEpPRuJSDDw/4B3PFuiZxVmx9PS3smeetuSzhjjX84Z6Kparaqb3Y+bgHIgq5em3wVeBOo8WqGHFebYiVFjjH86rzF0EckFZgAf9Xg+C7gJeOwc779LRIpEpKi+vv78KvWQscnRxIaH2Di6Mcbv9DvQRSQGpwf+PVXtuVPEz4H7VLXzbMdQ1cdVdbaqzk5JSTn/aj0gKEiYlh3HtoO2BIAxxr/0K9BFJBQnzJ9V1WW9NJkN/FlE9gGfBx4RkRs9VqWHFebEs6PmGK0nz/r7xxhjfEp/ZrkI8CRQrqoP99ZGVceoaq6q5gIvAN9S1Zc9WqkHFWbHcbJTKa+2LemMMf4jpB9tLgO+BGwXka3u534AjAZQ1bOOm49E3U+Mzhid4OVqjDHGM84Z6Kq6DpD+HlBV/24wBZ1TRzuULoOC20D6XdZnpI+KIDU23JbSNcb4Fd+7UnTbc/DS1+HV70LnyQEdQkQoyI5nq810Mcb4Ed8L9JlfhivuhS1/hD/dBq0DGwefnhPH3voWGk8M7JeCMcaMNL4X6CKw4F/g+v+BvWvgd0vhWNV5H6Zr5cWSSht2Mcb4B98L9C4zvwxffB6O7IMnroTa0vN6e0G2s8foVrti1BjjJ3w30AHGXwl3vgXqgqeWwJ7V/X5rfFQYY5KjbQkAY4zf8O1AB8gogK++C3HZ8OznYcuz/X5rQXaczXQxxvgN3w90cML879+G3LnwyrdgzUPQj31DC7PjqTnWauPoxhi/4B+BDhARB7f/FQpvhzX/Aa9825mzfhaLp6aRHBPGFx7fwLtltcNUqDHGDA3/CXSAkDC48RGY9wBsfRb+dAu09t37zk6I4tXvzGVMcjRf+2MRv1q1C+1Hz94YY0Yi/wp0cKY1zrsfbngE9q2Dp5ZCY2WfzTPjI/nrNy7hxulZ/Gz5J3z7T5tpaesYxoKNMcYz/C/Qu8z4InzxBTh6AJ5YCDXb+2waERrMw7cW8sOr83i7pIabH13PwcPHh7FYY4wZPP8NdIBx8+Ef3gEJcnrqu1f22VRE+NoVY3n6zgupOnqC63+1jvW7G4axWGOMGRz/DnSAtKnOtMaEXHj2Ftj8x7M2v2JiCq9+Zy7JMeF86amNPP3BpzaubozxCf4f6ACjMuHON2HsPHj1O7Dq3846rTE3OZqXvn0ZCyan8uPXyvjnF4pp67DNMIwxI1tgBDpAxCi4/S8w40uw9j/hpW+cdVpjTHgIv7ljFv+4cAJ/3VTBbb/ZQO2x1mEs2Bhjzk/gBDpAcKizqNf8f4HiP8OzN8OJvi/9DwoS/mnRRB67Yyaf1DZx3f+sY8uBI8NYsDHG9F9gBTo40xo/dy/c9BvY/6GzBkxt2VnfsiQ/g2XfupTw0CBu+80G/lp0cJiKNcaY/gu8QO9S+AW440VoqYPfXAFrf3rWDTMmp4/i1W/PZc6YBO59oZifvFZKR6drGAs2xpizC9xABxj7Ofj2Rsi7Flb9X/jtAqgp6bN5QnQYv7/zQv5h7hh+98E+vvzURo60nH15AWOMGS6BHegA0clwy9Nw6x+hqRoe/5yzuFcfJ0xDgoN48Nop/NcthRTtP8L1v17HjpqB7ZpkjDGeZIHeZcr1Tm996k3O4l6/nQ/V2/psfvOsbJ7/+iW0d7j4m0fW89b26mEs1hhjzmSB3l1UItz8BHzhOWiph8fnO0MxHW29Np+eE89r35nLpPRYvvnsZv5r+U4bVzfGeI0Fem8mXw3f2gAFtzonS3/zOajc3GvT1FER/Pmui7ltdg7/s2o31//qAzbtPzzMBRtjjAV636IS4abH4PbnnSV4n7gS3v0xnDzz4qLwkGAeunkaj3xxJkeOt3Pzox9y71+30dDce8/eGGOGgnhrnZLZs2drUVGRVz77vJ04Cst/CFuegeRJzprr2bN7bdrS1sEvV+3iyfc/JSosmHuXTOb2C0cTHCTDXLQxxh+JyCZV7TWArIfeH5HxcMOvnXnr7S3w5CJY/iCcPHFG0+jwEB5Ymsfb37ucqZlxPPhyCTf++gO22mbUxpghds5AF5EcEVktIuUiUioid/fS5osiUuy+rReRwqEp18vGXwnf+hBmfgXW/xIemwsHPuq9aWosf/raRfziC9OpPdbKTY98wAPLim3eujFmyJxzyEVEMoAMVd0sIrHAJuBGVS3r1uZSoFxVj4jIUuDHqnrR2Y7rU0Muvdm7Bl79Lhw9CBd/Cxb8C4RF9dq0qfUkv3h3F79bv4/YiBDuWzKZ22bnEGTDMMaY8zSoIRdVrVbVze7HTUA5kNWjzXpV7Vq1agOQPbiSfcDYefDND2HOV2HDr+Gxy2DfB702jY0I5V+uncIb/ziXiamxPLBsOzc9up7tFX3vd2qMMefrvE6KikgusBbIV9VeL48UkXuAyar61V5euwu4C2D06NGz9u/fP4CSR6BP33fWWT+yD8bOh4u+ARMWQ9CZvy9VlZe2VPLvb5ZzqKWdOy66gHsWTyIuKnT46zbG+Jyz9dD7HegiEgO8B/ybqi7ro8184BFgrqoeOtvxfH7Ipaf2FvjoMdj4BDRVQeJYuPDrMP12Zy32HhpPnOS/V3zCHz7cR0JUGPcvnczNM7NtGMYYc1aDDnQRCQVeB95R1Yf7aFMAvAQsVdVPznVMvwv0Lp0nofxV2PAYVGyEsFiYcQdc+DVIGndG89KqRh58uYTNB44y+4IE/vcN+UzJPPMXgDHGwCADXUQE+D1wWFW/10eb0cAq4Muqur4/RfltoHdXuQk++g2ULANXB0y8yhmOGTvPWZfdzeVSXthcwUNv7eDo8Xa+fEku/7R4IqMibBjGGPNZgw30ucD7wHaga6GSHwCjAVT1MRF5ArgZ6BoU7+jrA7sERKB3aaqBoqecW0s9pOTBRV+Hgts+MzPm6PF2frZ8J89+dICk6DD+9sLRfH5WNhckRXuxeGPMSOKRMXRPC6hA79LRBiUvwoZHoaYYIuJh1ldgztcgPudUs+KKo/zX8k9Yu6seVbhoTCK3zs5h6bR0osJCvPgNGGO8zQJ9pFGFAxvgo0eh/DVAnE02LvoGjL7k1HBMdeMJlm2u5K9FB9l36Dgx4SFcMy2DW+dkM3N0AiJ2AtWYQGOBPpIdPQgf/xY2/R5aj0J6AVz8Tci/GULCAWeq48f7jvB80UHe3F7N8fZOxqZEc8usHP5mZhZpoyK8/E0YY4aLBbovaG+B4uedqY/1OyAqyVlqYMznnK3y4pxrtZrbOnizuJq/bjrIx/uOECQwb1Iqt8zKZmFeGmEhtjyPMf7MAt2XqDrLCmx5xrk/3uA8nzTemR0z5nMw5nKITGBvfTMvbKrgxc0V1B5rIzE6jBumZ3LLrByb+miMn7JA91UuF9SVwafvwd73YN86ONkCCGROP9V778y+mLX7mnmhqIIVZbW0d7rIzxrFrbNzuL4wk/ioMG9/J8YYD7FA9xedJ5257XvXOAFfsdGZ3x4cDjkXwth5HMu4jJdqkvnL5hrKqo8RFhzEoqlp3Dg9iysmJhMeEuzt78IYMwgW6P6qrRkOfHg64Gu3O8+Hj4Lcy6lOupBlR8bzxI5QjpzoIDYihKumpnNdYSaXjksiNNjG243xNRbogaK5HvatdcJ97xo46lznpTHp1CdM58P2cfy1JoONbTnEREezNN8J9zm5ibajkjE+wgI9UB3+1Bl///R9OLgRGg8A4AoKZX/YBN47PoaNHeM4EJXPnMJ8rivMZEZOvM1vN2YEs0A3jqYaJ9grNsLBj9GqLUins5F1tSayyTWBPeFTiZ90KbMvmseUnGQLd2NGGAt007uOdqjZDhUbObl/A+37PiL6RDUAbRrKruBxtKbPIiv/CjLyPwejMgb2Oa5O6Gh1lj7oaINO970qJE+AIDtRa0x/WaCb/jtWTfPu9Rzc/h5BlR+T27aLcDkJQFN4OkHZM4mOCHd+GXS0Qmd772Hd0Xq6jXb2/XmxmVBwi7NQWdrUYfomjfFdFuhmwOoON7Jxw3vUlb1PauM28uQA4aFBREZGERsdQ1h4pLNEQdctuOtxRC/PdXstOMwJ+/LXYPe7zvTLtHwouBXyPw9xWecuzpgAZIFuPKLy6Ale31bF68XVbK909kOddUEC1xZkcM20DFIHuqZMSwOUvgTFf4GKjwFxroYt+ALkXdfrjk/GBCoLdONx+xpaeGN7Na9tq2JHTRMizjK/1xZksjQ/naSY8IEd+NAeZ02b4r/AkU+d3vykq6HwCzBuAQQPw6Yfrk4b1zcjlgW6GVK765p4bVs1rxVXsbe+heAg4dJxSVxXkMlVU9MHtgG2KlQUOcFe8iKcOOwsWJZ/szPenjXrM7s+nbe2ZucXxqE9cHgvHN7jTPM8tAeaa50F0eZ8FSYuhWBbg96MHBboZlioKuXVTbxeXMVrxVUcPHyC0GDhigkpXFuYwaIp6cSEDyAcO9phz0on3He+5Yy9J45zgr3gFmdD7t60NbnD2n07tPd0eDfXfrZtdKqz52viWIhMgNKX4ViFc9J29p0w88sQm37+tRvjYRboZtipKsUVjbxe7Iy5Vze2Eh4SxPxJqVxXmMmCyalEhg1gWKO10TmRWvwX54IpFLIvhCk3OEF/Krz3QEvdZ98bk+4EdtJY5z5xrPOLIXEMhMd+tm1nB+x6Bz5+AvasgqAQZzx/zlfhgssG99eBMYNggW68yuVSNh84wuvF1bxeXE1DcxtRYcEszEtjaX46n5uYQvRAeu6NFbD9BSfc68qc52IzTod04tjTve6EMRAeM7Bv4NAeZz/YLc84m5CkTHaCveA2O2Frhp0FuhkxOl3KR58e4vXiat4uqeFwSzthIUFcPj6ZxVPTuDIvbWAnVBsrITIewoZwQ+3241C6DDb+Fqq3Qmg0FN7mhLvNoTfDxALdjEgdnS6K9h9heWkt75TWUHn0BEECsy9IZPHUNK6amk5OYpS3y+xd5Sb4+EnnL4TONmcv2DlfhbzrIcTWnzdDxwLdjHiqSmnVMZaX1bK8tIYdNU0A5GWM4ip3uE9Ojx15a8scP+wMxRQ9CUf2QXSKcwJ11p0Qn+Pt6owfskA3Pmf/oRaWl9ayvKyGov1HUIXRiVEsnpLG4qnpzLogYWQt+etyOSdPP34CPnnbOWk6cYkT7AkXgAQB4jwvQafvOdfXuL8OcubGD+WQkvEJFujGp9U3tbGy3BmW+WD3Ido7XSRFh3FlXhpX5adx6bhkIkJH0IVAR/bDpqdh8x9O7wnrKaOyIXsWZM2G7DmQUQhhI3RYygwJC3TjN5rbOlizs47lpbWs3lFHU1sH0WHBzJuUyuKpacyblEpc5DBcTdofHW3ORiNtTc6FUiioy3msrnN83ctznW1QUwKVRXDUWdseCXZOyGbPgezZTtAnjYcg243KXw0q0EUkB/gDkA64gMdV9Rc92gjwC+Bq4Djwd6q6+WzHtUA3g9XW0cmGvYd5p7SGFWW11De1ERIkXDQ2kUV5aSyamk5WfKS3yxwazXXOlbSVRe77zdDunHcgIs65krarF581C6KTvFuv8ZjBBnoGkKGqm0UkFtgE3KiqZd3aXA18FyfQLwJ+oaoXne24FujGk1wuZWvFUVaU1bKirJbddc0ATM0cxaIpaSyaksaUjFEj76Sqp7g6oeETJ9wrPnZm4dSVuXv5OPPwu/fi06fZbBwf5dEhFxF5BfiVqq7o9txvgDWq+pz7653APFWt7us4FuhmKO2tbz4V7psOOCdVs+IjWTQljcVT0pgzJtH/N8lua4aqLad78RVF0FzjvBYU6ixxEBoJoVHOfVi0++tuz4VG9Xjsvg/r8XrSODthO0w8FugikgusBfJV9Vi3518HHlLVde6vVwL3qWpRj/ffBdwFMHr06Fn79+8/v+/EmAGob2pj1Q4n3N/f1UBbh4u4yFAWTE5l0ZQ0rpiYMrA1ZnyNKhyrdIK9eiucOAonj7tvJ9w39+P27s8fB86RExIEqVMga6bzF0DWLOeKWlvYzOM8EugiEgO8B/ybqi7r8dobwH/0CPR/VtVNfR3PeujGG463d/D+rgaWl9ayakctR46fJCw4iEvHJ7F4SjpX5qUOfF13f6XqnOA92SPku+5bj0FtqTPMU7nJWR4BnJ575gx3yM9ybnE5tg7OIA060EUkFHgdeEdVH+7ldRtyMT6no9PFpv1HWFFWy/KyWg4cPg7A9Jx4rp6WzjUFmf57UnWoqDqLo3WFe+UmqC52ZuiAs6plV7hnzXRukQnerdnHDPakqAC/Bw6r6vf6aHMN8B1OnxT9papeeLbjWqCbkURV+aS2mRVlNbxTWntqR6aZo+O5tiCTawoySLOe+8B0tENtiTvgNztj+g2fnH49aXy3kJ8FCbkQmWhTL/sw2ECfC7wPbMeZtgjwA2A0gKo+5g79XwFLcKYt3tlz/LwnC3QzknXtyPR6cTXl1ccQgTm5iVxXkMHSaRkkD3RHJuNobXSfsN0EFZuckO++Rr0EQ0yqs5RCTJr7ltrtlub09mNSnWmavjCM43I5G6aryznnMMDdt+zCImMGYXddM28UOzsy7a5rJkjgknFJXFuQyZKp6SRE2/S/QVOFY1VOyB+rdMK9uc59q4WWeufe1XHme4PD3YGfcjr4u8JegqDzJHS2u299PT7X6yedz1aXM0VU1Qlnlzugu4K6e2j3fK27uf8LrvzxgH5UFujGeEDXsEzXph2fNrQQEiRcNj6ZawsyWDw1feRcpeqPXC7nhOsZYd/tcdfzLfX0OTMnKBSCw5wecnDY6cch4Wc+1/U4KMR9C3avreO+D+r+uPtr4v66l9eCgpxNWcZcPqAfgwW6MR7WtTqks2lHFRVHThAWHMQVE5O5tiCTK6ekBcZUyJGqs8PZh1b1zJD2heGZs7BAN2YIqSrbKhp5fVsVb2z/7HZ71xZmMH9S6sB2ZDKmFxnB6xYAAAxPSURBVBboxgyT7tvtvbG9mvqmNsJDgrhiYgpLpqZzZV4acVE2LGMGzgLdGC/odCkf7zvM2yU1vFNaQ3VjKyFBwiXjkrhqajqLp6aRGmtTIc35sUA3xstUleKKRt4ureHtkho+bWhBBGaNTmBJfvrI3m7PjCgW6MaMIKrKrrpm3i5xwr2s2lkWaWrmKJZMTWdJfjrjU2P8d2VIMygW6MaMYAcOHeed0hreKqlm8wFnHZSxKdGnwn1aVpyFuznFAt0YH1F7rJXlpTW8XVrDhr2H6XQpWfGRLJ6axpKp6czOTRxZe6maYWeBbowPOtLSzrvuvVTX7mqgvcNFYnTY6WV/J6QQGTaC9lI1w8IC3Rgf17WX6oqyWlbtqKOptYPwkCAun5DMoilpLMxLs/VlAoQFujF+5GSni42fHj61I1Pl0ROIwMzRCae22xuXEuPtMs0QsUA3xk+pKmXVx1he6oR714yZsSnRp7bbm56TYOPufsQC3ZgAUXHkOO+W1bKivJaP9h6mw6Ukx4SxcLLTc587IZmIUBt392UW6MYEoMYTJ1mzs47lZbW8t7Oe5rYOIkODT427L56SbssQ+CALdGMCXFtHJxv2HmZFWQ3vltVRc6yVsOAgFkxO5cYZWcyfnEJ4iPXcfYEFujHmlK7VIV/ZWslr26poaG5nVEQI1xRkctOMLGZfkECQjbmPWBboxphedXS6WLe7gZe3VPJOaS0nTnaSnRDJjdOzuHFGJuNTY71dounBAt0Yc04tbR0sL6vhpS1VrNtVj0thWlYcN0zP5PrCTFJtk+wRwQLdGHNe6ppaeW1bNS9vqWR7ZSNBApeNT+amGVlcNTXdNuzwIgt0Y8yA7a5r4uUtVby0pZLKoyeIDA3mqqlp3Dgji7njkwkJDvJ2iQHFAt0YM2gul7LpwBFe2lLJG8XVNJ44SXJMGNcWZLJoShqzLkiwOe7DwALdGONRbR2drNlZz8tbKlm5o472DhfhIUHMyU3ksvHJzB2fzJTMUXaF6hCwQDfGDJnmtg42fnqIdbsOsX5PAztqmgCIjwrlkrFJpwL+gqQoW9fdA84W6HZmwxgzKDHhISyYnMaCyWmAc0L1wz2HWLergXW7G3irpAaArPhI5o5P5rIJyVw6LslWhxwC1kM3xgwZVeXThhY+2O2E+/o9h2hq7QBgcnrsqYC/MDfRZs7006CGXETkKeBaoE5V83t5PQ54BhiN0+P/mar+7lxFWaAbE3g6XUpJZSPrdjfwwe4GivYdob3TRWiwMGN0AnPHJ7MwL5UpGaNseKYPgw30K4Bm4A99BPoPgDhVvU9EUoCdQLqqtp/tuBboxpgT7Z0U7T98KuBLq46hCrlJUSydlsHV+RnkZ1m4dzeoMXRVXSsiuWdrAsSK8xOPAQ4DHQOo0xgTYCLDgrl8QgqXT0gBoKG5jRVltby5vZrH1+7l0TV7yEmM5Or8DJZOy6Aw2zbMPpt+jaG7A/31PnroscCrwGQgFrhNVd/o4zh3AXcBjB49etb+/fsHXLgxxr8daWlnRVktb2yv5oPdDXS4N8xemp/O0mkZzMiJD8hFxAY9bfEcgf554DLgn4BxwAqgUFWPne2YNuRijOmvxuMnWVFey1vbq3l/VwPtnS7SR0WwJD+dawoymDU6cFaIHOppi3cCD6nzm2G3iHyK01vf6IFjG2MMcVGhfH5WNp+flc2x1pOsLK/lze01/GnjAZ5ev4/U2HCW5Kdz9bQM5uQmBuwFTZ4I9APAQuB9EUkDJgF7PXBcY4w5w6iIUG6akc1NM7Jpaj3Jqh11vLW9hr98fJA/fLif5JgwrpqazjXTMrhwTGJArTXTn1kuzwHzgGSgFvhXIBRAVR8TkUzgaSADEJze+jPn+mAbcjHGeFJLWwerdzrhvmpHHSdOdjIqIoQrJqawYHIq8yalkhgd5u0yB80u/TfGBJTj7R2s/aSeleV1rN5ZT0NzGyIwIyeeBZNTmT/Zd+e6W6AbYwKWy6WUVDW6w72O4opGANJHRTB/cgrzJ6Uyd0IyUWG+caWqBboxxrjVNbWyZmc9q3fU8f6uBprbOggLDuLicUksmJTCgslpjE6K8naZfbJAN8aYXrR3uPh432FW7ahj9Y469ja0ADAuJfrU0Myc3ERCR9CJVQt0Y4zph30NLU6476zjo72Hae90ERt++sTq/MneP7FqgW6MMeeppa2DdbsbWL2jjlU76qhraiNIYOboBBbmpXFlXirjU2OG/cSqBboxxgyCy6WUVh3j3fJaVu6opaTSuRB+dGIUC/NSuTIvjTm5iYSFDP3QjAW6McZ4UE1jKyt31LKyvI4PdjfQ1uEempmUwpV5qcybmErCEA3NWKAbY8wQOd7ewbpdDawsr2Pljjoamp2hmdkXJLIwL5WFeWmMS4n22NCMBboxxgwDl0sprmxkZXkt75bXUV7tDM3kJkWxMC+NhXmDnzVjgW6MMV5QefQEq9zh/uGeQ86smYgQ7l44ga9ePnZAx7RNoo0xxguy4iP50iW5fOmSXFraOnh/VwMry2tJGxUxJJ9ngW6MMcMgOjyEJfnpLMlPH7LPGDmXPxljjBkUC3RjjPETFujGGOMnLNCNMcZPWKAbY4yfsEA3xhg/YYFujDF+wgLdGGP8hNcu/ReRemD/AN+eDDR4sBxPGal1wcitzeo6P1bX+fHHui5Q1ZTeXvBaoA+GiBT1tZaBN43UumDk1mZ1nR+r6/wEWl025GKMMX7CAt0YY/yErwb6494uoA8jtS4YubVZXefH6jo/AVWXT46hG2OMOZOv9tCNMcb0YIFujDF+wucCXUSWiMhOEdktIvd7ux4AEckRkdUiUi4ipSJyt7dr6k5EgkVki4i87u1auohIvIi8ICI73D+3S7xdE4CI/C/3f8MSEXlORIZma5lz1/GUiNSJSEm35xJFZIWI7HLfJ4yQun7q/u9YLCIviUj8cNfVV23dXrtHRFREkkdKXSLyXXeWlYrIf3ris3wq0EUkGPg1sBSYAvytiEzxblUAdADfV9U84GLg2yOkri53A+XeLqKHXwBvq+pkoJARUJ+IZAH/CMxW1XwgGPiCl8p5GljS47n7gZWqOgFY6f56uD3NmXWtAPJVtQD4BHhguItye5oza0NEcoBFwIHhLsjtaXrUJSLzgRuAAlWdCvzMEx/kU4EOXAjsVtW9qtoO/Bnnh+JVqlqtqpvdj5twwinLu1U5RCQbuAZ4wtu1dBGRUcAVwJMAqtquqke9W9UpIUCkiIQAUUCVN4pQ1bXA4R5P3wD83v3498CNw1oUvdelqstVtcP95QYge7jrctfR288M4L+Bfwa8MgOkj7q+CTykqm3uNnWe+CxfC/Qs4GC3rysYIcHZRURygRnAR96t5JSf4/zP7PJ2Id2MBeqB37mHgp4QkWhvF6WqlTg9pQNANdCoqsu9W9VnpKlqNTidCCDVy/X05u+Bt7xdRBcRuR6oVNVt3q6lh4nA5SLykYi8JyJzPHFQXwt06eW5ETPvUkRigBeB76nqsRFQz7VAnapu8nYtPYQAM4FHVXUG0IJ3hg8+wz0mfQMwBsgEokXkDu9W5TtE5Ic4w4/PersWABGJAn4I/MjbtfQiBEjAGaK9F3heRHrLt/Pia4FeAeR0+zobL/1J3JOIhOKE+bOquszb9bhdBlwvIvtwhqcWiMgz3i0JcP47Vqhq118xL+AEvLddCXyqqvWqehJYBlzq5Zq6qxWRDAD3vUf+TPcEEfkKcC3wRR05F7eMw/nlvM39byAb2Cwi6V6tylEBLFPHRpy/oAd9wtbXAv1jYIKIjBGRMJwTVq96uSbcv1mfBMpV9WFv19NFVR9Q1WxVzcX5Wa1SVa/3OFW1BjgoIpPcTy0EyrxYUpcDwMUiEuX+b7qQEXCytptXga+4H38FeMWLtZwiIkuA+4DrVfW4t+vpoqrbVTVVVXPd/wYqgJnu//+87WVgAYCITATC8MCqkD4V6O4TL98B3sH5h/a8qpZ6tyrA6Ql/CacHvNV9u9rbRY1w3wWeFZFiYDrw716uB/dfDC8Am4HtOP8+vHLpuIg8B3wITBKRChH5B+AhYJGI7MKZtfHQCKnrV0AssML9//5jw13XWWrzuj7qegoY657K+GfgK574y8Yu/TfGGD/hUz10Y4wxfbNAN8YYP2GBbowxfsIC3Rhj/IQFujHG+AkLdGOM8RMW6MYY4yf+P4qzM6zC+axZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Diagnostic plot\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dictionary to convert the index to word for target and source vocabulary\n",
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to implement the interface\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to convert an integer sequence to a word sequence for summary as well as the reviews\n",
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: chips pretty delicious even original flavor nothing good delicious also fried either definitely good snack times day \n",
      "Original summary: pretty delicious \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: regular customers delicious coffee purchase french roast also makes single fresh cup time coffee maker \n",
      "Original summary: love coffee \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: love powder must blends may recommend powder try different peppers different amounts amazing results \n",
      "Original summary: good quality price \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: due year say coffee best substitute keurig based cafe attempt tasty dark blend look emeril time head cup \n",
      "Original summary: dark blend to coffee \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: bars taste lot like candy least quite awhile plan one warning easy digestion eat slowly tempted eat one \n",
      "Original summary: tastes pretty to candy \n",
      "Predicted summary:  great\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print(\"Review:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
